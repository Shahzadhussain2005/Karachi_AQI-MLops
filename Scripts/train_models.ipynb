import pandas as pd
import numpy as np
from datetime import datetime
import pickle
import json
import os
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
import xgboost as xgb
import lightgbm as lgb

print("="*70)
print("ADVANCED AQI PREDICTION - WITH HYPERPARAMETER TUNING (OPTIMIZED)")
print("="*70)

os.makedirs('models', exist_ok=True)

# ============================================================================
# 1. Load Data
# ============================================================================

def load_from_mongodb(uri, max_attempts=2):
    """Try MongoDB"""
    from pymongo import MongoClient
    from pymongo.server_api import ServerApi
    
    for attempt in range(max_attempts):
        try:
            print(f"\nAttempt {attempt + 1}/{max_attempts}: Connecting to MongoDB...")
            client = MongoClient(uri, server_api=ServerApi('1'),
                               serverSelectionTimeoutMS=5000, connectTimeoutMS=5000)
            client.admin.command('ping')
            print("âœ“ Connected!")
            
            db = client['aqi_feature_store']
            collection = db['aqi_features']
            data = pd.DataFrame(list(collection.find({}, {"_id": 0})))
            client.close()
            
            print(f"âœ“ Loaded {len(data)} records from MongoDB")
            return data, 'mongodb'
        except Exception as e:
            print(f"âœ— Failed: {str(e)[:80]}")
    return None, None

def load_from_csv(csv_path):
    """Load from CSV"""
    try:
        print(f"\nLoading from CSV: {csv_path}")
        data = pd.read_csv(csv_path)
        print(f"âœ“ Loaded {len(data)} records")
        return data, 'csv'
    except:
        return None, None

print("\n1. Loading data...")

MONGO_URI = "mongodb+srv://nawababbas08_db_user:2Ja4OGlDdKfG6EvZ@cluster0.jnxn95g.mongodb.net/?retryWrites=true&w=majority&tlsAllowInvalidCertificates=true"
CSV_PATH = "data/cleaned_aqi_data_v2.csv"

data, source = load_from_mongodb(MONGO_URI, 2)
if data is None:
    print("\nâš ï¸ MongoDB failed, using CSV...")
    data, source = load_from_csv(CSV_PATH)

if data is None:
    print("\nâœ— ERROR: No data source available")
    exit(1)

print(f"\nâœ“ Source: {source.upper()}")
print(f"âœ“ Records: {len(data)}")

# ============================================================================
# 2. Enhanced Feature Engineering
# ============================================================================

print("\n2. Engineering features...")

if 'time' in data.columns:
    data['time'] = pd.to_datetime(data['time'])
    data = data.sort_values('time').reset_index(drop=True)
elif 'timestamp' in data.columns:
    data['timestamp'] = pd.to_datetime(data['timestamp'])
    data = data.sort_values('timestamp').reset_index(drop=True)

# More comprehensive lag features
print("   Creating lag features...")
for lag in [1, 2, 3, 6, 12, 24, 48]:
    if 'aqi' in data.columns:
        data[f'aqi_lag_{lag}h'] = data['aqi'].shift(lag)
    if 'pm2_5' in data.columns:
        data[f'pm25_lag_{lag}h'] = data['pm2_5'].shift(lag)

# Rolling statistics (mean, std, min, max)
print("   Creating rolling features...")
for window in [3, 6, 12, 24]:
    if 'aqi' in data.columns:
        data[f'aqi_ma_{window}h'] = data['aqi'].rolling(window=window, min_periods=1).mean()
        data[f'aqi_std_{window}h'] = data['aqi'].rolling(window=window, min_periods=1).std()
        data[f'aqi_min_{window}h'] = data['aqi'].rolling(window=window, min_periods=1).min()
        data[f'aqi_max_{window}h'] = data['aqi'].rolling(window=window, min_periods=1).max()

# Difference features (trend detection)
print("   Creating difference features...")
if 'aqi' in data.columns:
    data['aqi_diff_1h'] = data['aqi'].diff(1)
    data['aqi_diff_3h'] = data['aqi'].diff(3)
    data['aqi_diff_24h'] = data['aqi'].diff(24)

# Cyclical features (better encoding)
if 'hour' in data.columns:
    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)
    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)

if 'day_of_week' in data.columns:
    data['dow_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)
    data['dow_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)

if 'month' in data.columns:
    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)
    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)

# Targets
data['aqi_24h'] = data['aqi'].shift(-24)
data['aqi_48h'] = data['aqi'].shift(-48)
data['aqi_72h'] = data['aqi'].shift(-72)

# Remove rows with all NaN
data = data.dropna(axis=1, how='all')

print(f"âœ“ After engineering: {data.shape[0]} records, {data.shape[1]} columns")

# ============================================================================
# 3. Prepare Data with Better Filtering
# ============================================================================

print("\n3. Preparing features...")

# Exclude target columns and categorical/string columns
exclude_cols = ['time', 'timestamp', 'aqi_24h', 'aqi_48h', 'aqi_72h',
                'dominant_pollutant', 'aqi_category', 'aqi_color', 'time_of_day',
                'season', 'weather_condition', 'day_of_week', 'day_of_month',
                'is_weekend']

# Get only numeric columns for features
feature_cols = [col for col in data.columns if col not in exclude_cols]
numeric_cols = data[feature_cols].select_dtypes(include=[np.number]).columns.tolist()
feature_cols = numeric_cols

print(f"âœ“ Initial features: {len(feature_cols)}")

# Remove features with too many missing values
missing_threshold = 0.3
for col in feature_cols[:]:
    missing_pct = data[col].isnull().sum() / len(data)
    if missing_pct > missing_threshold:
        feature_cols.remove(col)
        print(f"   Removed {col} (missing: {missing_pct*100:.1f}%)")

print(f"âœ“ After removing high-missing features: {len(feature_cols)}")

# Handle remaining missing values
data[feature_cols] = data[feature_cols].fillna(data[feature_cols].mean())

# Remove rows where target is missing
data = data.dropna(subset=['aqi_24h', 'aqi_48h', 'aqi_72h'])

print(f"âœ“ Final dataset: {len(data)} records")

X = data[feature_cols]
y_24h = data['aqi_24h']
y_48h = data['aqi_48h']
y_72h = data['aqi_72h']

# Remove any remaining NaN
X = X.fillna(X.mean())

print(f"âœ“ Features: {len(feature_cols)}")
print(f"âœ“ Samples: {len(X)}")

# ============================================================================
# 4. Feature Selection
# ============================================================================

print("\n4. Feature selection...")

def select_best_features(X, y, k=30):
    """Select top K most important features"""
    if len(X.columns) <= k:
        return X.columns.tolist()
    
    # Use mutual information for feature selection
    selector = SelectKBest(score_func=mutual_info_regression, k=k)
    selector.fit(X, y)
    
    # Get selected feature names
    selected_features = X.columns[selector.get_support()].tolist()
    
    # Get scores
    scores = selector.scores_
    feature_scores = list(zip(X.columns, scores))
    feature_scores.sort(key=lambda x: x[1], reverse=True)
    
    print(f"   Top 10 features:")
    for feat, score in feature_scores[:10]:
        print(f"      {feat:30s}: {score:.3f}")
    
    return selected_features

# Select features for 24h prediction
selected_features = select_best_features(X, y_24h, k=min(30, len(X.columns)))
X = X[selected_features]

print(f"\nâœ“ Selected {len(selected_features)} best features")

# ============================================================================
# 5. Time Series Split (Better for Time Series!)
# ============================================================================

print("\n5. Splitting data (time-series aware)...")

# Use 80-20 split but maintain time order
split_idx = int(len(X) * 0.8)
X_train, X_test = X[:split_idx], X[split_idx:]
y_24h_train, y_24h_test = y_24h[:split_idx], y_24h[split_idx:]
y_48h_train, y_48h_test = y_48h[:split_idx], y_48h[split_idx:]
y_72h_train, y_72h_test = y_72h[:split_idx], y_72h[split_idx:]

# Use RobustScaler (better for outliers)
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

with open('models/scaler_ml.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print(f"âœ“ Train: {len(X_train)}, Test: {len(X_test)}")

# ============================================================================
# 6. Define Model Hyperparameter Grids (OPTIMIZED!)
# ============================================================================

print("\n6. Setting up hyperparameter grids (optimized)...")

# MUCH SMALLER GRIDS - will run in 5-10 minutes instead of hours!
param_grids = {
    'Ridge': {
        'model': Ridge(),
        'params': {
            'alpha': [0.1, 1.0, 10.0]  # Reduced from 4 to 3 values
        },
        'n_iter': 3  # GridSearch will try all 3
    },
    'Lasso': {
        'model': Lasso(max_iter=5000),
        'params': {
            'alpha': [0.01, 0.1, 1.0]  # Reduced from 4 to 3 values
        },
        'n_iter': 3
    },
    'Random Forest': {
        'model': RandomForestRegressor(random_state=42, n_jobs=-1),
        'params': {
            'n_estimators': [50, 100],  # Reduced from 3 to 2
            'max_depth': [10, None],  # Reduced from 4 to 2
            'min_samples_split': [5, 10]  # Reduced from 3 to 2
        },
        'n_iter': 8  # Will sample 8 random combinations instead of all 48
    },
    'Gradient Boosting': {
        'model': GradientBoostingRegressor(random_state=42),
        'params': {
            'n_estimators': [50, 100],  # Reduced
            'learning_rate': [0.05, 0.1],  # Reduced
            'max_depth': [3, 5]  # Reduced
        },
        'n_iter': 8
    },
    'XGBoost': {
        'model': xgb.XGBRegressor(random_state=42, n_jobs=-1),
        'params': {
            'n_estimators': [50, 100],
            'learning_rate': [0.05, 0.1],
            'max_depth': [3, 5],
            'subsample': [0.8, 1.0]
        },
        'n_iter': 10
    },
    'LightGBM': {
        'model': lgb.LGBMRegressor(random_state=42, verbose=-1, n_jobs=-1),
        'params': {
            'n_estimators': [50, 100],
            'learning_rate': [0.05, 0.1],
            'max_depth': [3, 5],
            'num_leaves': [31, 63]
        },
        'n_iter': 10
    }
}

print(f"âœ“ {len(param_grids)} models configured for tuning")
print(f"âœ“ Using RandomizedSearchCV for faster training")

# ============================================================================
# 7. Evaluation Function
# ============================================================================

def evaluate(y_true, y_pred):
    """Comprehensive evaluation metrics"""
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # Accuracy within thresholds
    acc_20 = np.sum(np.abs(y_true - y_pred) <= 20) / len(y_true) * 100
    acc_10 = np.sum(np.abs(y_true - y_pred) <= 10) / len(y_true) * 100
    acc_5 = np.sum(np.abs(y_true - y_pred) <= 5) / len(y_true) * 100
    
    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100
    
    return {
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2,
        'MAPE': mape,
        'Acc20': acc_20,
        'Acc10': acc_10,
        'Acc5': acc_5
    }

# ============================================================================
# 8. Training with RandomizedSearchCV (FASTER!)
# ============================================================================

print("\n" + "="*70)
print("TRAINING MODELS WITH HYPERPARAMETER TUNING (OPTIMIZED)")
print("="*70)
print("\nâ±ï¸  This should take 5-10 minutes...")

results = {}

# Time series cross-validation - REDUCED to 2 splits for speed
tscv = TimeSeriesSplit(n_splits=2)  # Changed from 3 to 2

for horizon, y_train, y_test in [
    ('24h', y_24h_train, y_24h_test),
    ('48h', y_48h_train, y_48h_test),
    ('72h', y_72h_train, y_72h_test)
]:
    print(f"\n{'='*70}")
    print(f"TRAINING FOR {horizon} AHEAD PREDICTION")
    print('='*70)
    
    results[horizon] = {}
    
    for name, config in param_grids.items():
        print(f"\n{name}...")
        print(f"   Tuning hyperparameters...")
        
        # Use RandomizedSearchCV for most models (faster than GridSearchCV)
        if name in ['Ridge', 'Lasso']:
            # GridSearch for simple models (fast anyway)
            from sklearn.model_selection import GridSearchCV
            search = GridSearchCV(
                estimator=config['model'],
                param_grid=config['params'],
                cv=tscv,
                scoring='r2',
                n_jobs=-1,
                verbose=0
            )
        else:
            # RandomizedSearch for complex models (much faster)
            search = RandomizedSearchCV(
                estimator=config['model'],
                param_distributions=config['params'],
                n_iter=config['n_iter'],  # Only try N random combinations
                cv=tscv,
                scoring='r2',
                n_jobs=-1,
                verbose=0,
                random_state=42
            )
        
        # Fit search
        search.fit(X_train_scaled, y_train)
        
        # Best model
        best_model = search.best_estimator_
        
        print(f"   Best params: {search.best_params_}")
        print(f"   Best CV RÂ²: {search.best_score_:.3f}")
        
        # Predictions
        y_pred_train = best_model.predict(X_train_scaled)
        y_pred_test = best_model.predict(X_test_scaled)
        
        # Evaluate
        train_metrics = evaluate(y_train, y_pred_train)
        test_metrics = evaluate(y_test, y_pred_test)
        
        # Store results
        results[horizon][name] = {
            'test_R2': test_metrics['R2'],
            'test_RMSE': test_metrics['RMSE'],
            'test_MAE': test_metrics['MAE'],
            'test_MAPE': test_metrics['MAPE'],
            'test_Acc20': test_metrics['Acc20'],
            'test_Acc10': test_metrics['Acc10'],
            'test_Acc5': test_metrics['Acc5'],
            'train_R2': train_metrics['R2'],
            'cv_R2': search.best_score_,
            'best_params': search.best_params_
        }
        
        # Display metrics
        print(f"\n   ğŸ“Š Results:")
        print(f"      Test RÂ²:    {test_metrics['R2']:6.3f}")
        print(f"      Train RÂ²:   {train_metrics['R2']:6.3f}")
        print(f"      CV RÂ²:      {search.best_score_:6.3f}")
        print(f"      RMSE:       {test_metrics['RMSE']:6.2f}")
        print(f"      MAE:        {test_metrics['MAE']:6.2f}")
        print(f"      MAPE:       {test_metrics['MAPE']:6.2f}%")
        print(f"      Acc Â±20:    {test_metrics['Acc20']:6.1f}%")
        print(f"      Acc Â±10:    {test_metrics['Acc10']:6.1f}%")
        
        # Check for overfitting
        overfit_gap = train_metrics['R2'] - test_metrics['R2']
        if overfit_gap > 0.2:
            print(f"      âš ï¸  OVERFITTING (gap: {overfit_gap:.3f})")
        elif test_metrics['R2'] < 0:
            print(f"      âš ï¸  NEGATIVE RÂ² - Model performs worse than baseline!")
        elif test_metrics['R2'] < 0.1:
            print(f"      âš ï¸  VERY LOW RÂ² - Check data quality")
        else:
            print(f"      âœ“  Good performance!")
        
        # Save model
        model_path = f'models/{name.lower().replace(" ", "_")}_{horizon}.pkl'
        with open(model_path, 'wb') as f:
            pickle.dump(best_model, f)
        print(f"      âœ“  Saved: {model_path}")

# ============================================================================
# 9. Feature Importance Analysis
# ============================================================================

print("\n" + "="*70)
print("FEATURE IMPORTANCE ANALYSIS")
print("="*70)

# Analyze feature importance for best model
best_24h = max(results['24h'].items(), key=lambda x: x[1]['test_R2'])
print(f"\nBest 24h model: {best_24h[0]} (RÂ² = {best_24h[1]['test_R2']:.3f})")

# Save feature importance if available
feature_importance_path = 'models/feature_importance.csv'
try:
    # Load the best model
    model_name = best_24h[0].lower().replace(" ", "_")
    with open(f'models/{model_name}_24h.pkl', 'rb') as f:
        best_model = pickle.load(f)
    
    # Get feature importance
    if hasattr(best_model, 'feature_importances_'):
        importance_df = pd.DataFrame({
            'feature': selected_features,
            'importance': best_model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        importance_df.to_csv(feature_importance_path, index=False)
        
        print(f"\nTop 15 Most Important Features:")
        for idx, row in importance_df.head(15).iterrows():
            print(f"   {row['feature']:30s}: {row['importance']:.4f}")
        
        print(f"\nâœ“ Feature importance saved to: {feature_importance_path}")
except Exception as e:
    print(f"\nâš ï¸ Could not extract feature importance: {str(e)}")

# ============================================================================
# 10. Summary
# ============================================================================

print("\n" + "="*70)
print("RESULTS SUMMARY")
print("="*70)

for horizon in results.keys():
    print(f"\n{horizon} Ahead:")
    print("-" * 70)
    
    best = max(results[horizon].items(), key=lambda x: x[1]['test_R2'])
    
    for name in results[horizon]:
        m = results[horizon][name]
        marker = " â˜… BEST" if name == best[0] else ""
        print(f"{name:18s}: RÂ²={m['test_R2']:7.3f}  RMSE={m['test_RMSE']:6.2f}  "
              f"MAE={m['test_MAE']:6.2f}  AccÂ±20={m['test_Acc20']:5.1f}%{marker}")

# Save results
with open('models/ml_tuned_results.json', 'w') as f:
    # Convert to serializable format
    results_serializable = {}
    for horizon in results:
        results_serializable[horizon] = {}
        for model_name in results[horizon]:
            results_serializable[horizon][model_name] = {
                k: v for k, v in results[horizon][model_name].items() 
                if k != 'best_params'
            }
            results_serializable[horizon][model_name]['best_params_str'] = str(
                results[horizon][model_name]['best_params']
            )
    
    json.dump(results_serializable, f, indent=2)

print("\n" + "="*70)
print("âœ… TRAINING COMPLETE!")
print("="*70)
print(f"\nğŸ“Š Source: {source.upper()}")
print(f"ğŸ“ˆ Models: {len(param_grids)} ML models Ã— 3 horizons = {len(param_grids)*3} total")
print(f"ğŸ¯ All models hyperparameter-tuned with RandomizedSearchCV")
print("\nğŸ“ Saved:")
print("  âœ“ models/*.pkl (tuned models)")
print("  âœ“ models/scaler_ml.pkl")
print("  âœ“ models/ml_tuned_results.json")
print("  âœ“ models/feature_importance.csv")

# ============================================================================
# 11. Diagnostic Information
# ============================================================================

print("\n" + "="*70)
print("DIAGNOSTIC INFORMATION")
print("="*70)

print(f"\nData Quality:")
print(f"   Total samples: {len(data)}")
print(f"   Training samples: {len(X_train)}")
print(f"   Test samples: {len(X_test)}")
print(f"   Features used: {len(selected_features)}")

print(f"\nTarget Statistics (24h ahead):")
print(f"   Mean: {y_24h.mean():.2f}")
print(f"   Std: {y_24h.std():.2f}")
print(f"   Min: {y_24h.min():.2f}")
print(f"   Max: {y_24h.max():.2f}")

print(f"\nBest Model Performance:")
best_overall = max(
    [(h, n, m['test_R2']) for h in results for n, m in results[h].items()],
    key=lambda x: x[2]
)
print(f"   {best_overall[1]} ({best_overall[0]}): RÂ² = {best_overall[2]:.3f}")

