{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9502795-5458-4bd8-8db0-ba07ef661efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AQI PREDICTION - ML MODELS (NO TENSORFLOW)\n",
      "======================================================================\n",
      "\n",
      "1. Loading data...\n",
      "\n",
      "Attempt 1/2: Connecting to MongoDB...\n",
      "‚úì Connected!\n",
      "‚úì Loaded 4340 records from MongoDB\n",
      "\n",
      "‚úì Source: MONGODB\n",
      "‚úì Records: 4340\n",
      "\n",
      "2. Engineering features...\n",
      "‚úì After engineering: 4244 records\n",
      "\n",
      "3. Preparing features...\n",
      "‚úì Features: 43\n",
      "‚úì Samples: 4244\n",
      "\n",
      "4. Splitting and scaling...\n",
      "‚úì Train: 3395, Test: 849\n",
      "\n",
      "======================================================================\n",
      "TRAINING ML MODELS\n",
      "======================================================================\n",
      "\n",
      "24h Ahead:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Ridge...\n",
      "  Test R¬≤:   -0.032\n",
      "  RMSE:      57.21\n",
      "  Acc ¬±20:   44.8%\n",
      "  Train R¬≤:  0.186\n",
      "  ‚úì Saved: models/ridge_24h.pkl\n",
      "\n",
      "Gradient Boosting...\n",
      "  Test R¬≤:   -0.203\n",
      "  RMSE:      61.78\n",
      "  Acc ¬±20:   44.3%\n",
      "  Train R¬≤:  0.883\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/gradient_boosting_24h.pkl\n",
      "\n",
      "Random Forest...\n",
      "  Test R¬≤:   -0.090\n",
      "  RMSE:      58.79\n",
      "  Acc ¬±20:   46.4%\n",
      "  Train R¬≤:  0.629\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/random_forest_24h.pkl\n",
      "\n",
      "XGBoost...\n",
      "  Test R¬≤:   -0.156\n",
      "  RMSE:      60.57\n",
      "  Acc ¬±20:   46.5%\n",
      "  Train R¬≤:  0.563\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/xgboost_24h.pkl\n",
      "\n",
      "LightGBM...\n",
      "  Test R¬≤:   -0.052\n",
      "  RMSE:      57.76\n",
      "  Acc ¬±20:   45.3%\n",
      "  Train R¬≤:  0.477\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/lightgbm_24h.pkl\n",
      "\n",
      "48h Ahead:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Ridge...\n",
      "  Test R¬≤:   -0.017\n",
      "  RMSE:      59.99\n",
      "  Acc ¬±20:   49.0%\n",
      "  Train R¬≤:  0.133\n",
      "  ‚úì Saved: models/ridge_48h.pkl\n",
      "\n",
      "Gradient Boosting...\n",
      "  Test R¬≤:   -0.226\n",
      "  RMSE:      65.89\n",
      "  Acc ¬±20:   44.1%\n",
      "  Train R¬≤:  0.879\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/gradient_boosting_48h.pkl\n",
      "\n",
      "Random Forest...\n",
      "  Test R¬≤:   -0.251\n",
      "  RMSE:      66.55\n",
      "  Acc ¬±20:   36.9%\n",
      "  Train R¬≤:  0.685\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/random_forest_48h.pkl\n",
      "\n",
      "XGBoost...\n",
      "  Test R¬≤:   -0.065\n",
      "  RMSE:      61.41\n",
      "  Acc ¬±20:   45.5%\n",
      "  Train R¬≤:  0.628\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/xgboost_48h.pkl\n",
      "\n",
      "LightGBM...\n",
      "  Test R¬≤:   -0.059\n",
      "  RMSE:      61.22\n",
      "  Acc ¬±20:   45.1%\n",
      "  Train R¬≤:  0.517\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/lightgbm_48h.pkl\n",
      "\n",
      "72h Ahead:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Ridge...\n",
      "  Test R¬≤:   -0.008\n",
      "  RMSE:      58.16\n",
      "  Acc ¬±20:   48.5%\n",
      "  Train R¬≤:  0.121\n",
      "  ‚úì Saved: models/ridge_72h.pkl\n",
      "\n",
      "Gradient Boosting...\n",
      "  Test R¬≤:   -0.436\n",
      "  RMSE:      69.42\n",
      "  Acc ¬±20:   46.1%\n",
      "  Train R¬≤:  0.882\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/gradient_boosting_72h.pkl\n",
      "\n",
      "Random Forest...\n",
      "  Test R¬≤:   -0.502\n",
      "  RMSE:      70.99\n",
      "  Acc ¬±20:   41.3%\n",
      "  Train R¬≤:  0.666\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/random_forest_72h.pkl\n",
      "\n",
      "XGBoost...\n",
      "  Test R¬≤:   -0.176\n",
      "  RMSE:      62.83\n",
      "  Acc ¬±20:   47.5%\n",
      "  Train R¬≤:  0.597\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/xgboost_72h.pkl\n",
      "\n",
      "LightGBM...\n",
      "  Test R¬≤:   -0.025\n",
      "  RMSE:      58.66\n",
      "  Acc ¬±20:   47.8%\n",
      "  Train R¬≤:  0.516\n",
      "  ‚ö†Ô∏è OVERFITTING\n",
      "  ‚úì Saved: models/lightgbm_72h.pkl\n",
      "\n",
      "======================================================================\n",
      "RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "24h Ahead:\n",
      "----------------------------------------------------------------------\n",
      "Ridge             : R¬≤=-0.032  RMSE= 57.21  Acc¬±20= 44.8% ‚òÖ\n",
      "Gradient Boosting : R¬≤=-0.203  RMSE= 61.78  Acc¬±20= 44.3%\n",
      "Random Forest     : R¬≤=-0.090  RMSE= 58.79  Acc¬±20= 46.4%\n",
      "XGBoost           : R¬≤=-0.156  RMSE= 60.57  Acc¬±20= 46.5%\n",
      "LightGBM          : R¬≤=-0.052  RMSE= 57.76  Acc¬±20= 45.3%\n",
      "\n",
      "48h Ahead:\n",
      "----------------------------------------------------------------------\n",
      "Ridge             : R¬≤=-0.017  RMSE= 59.99  Acc¬±20= 49.0% ‚òÖ\n",
      "Gradient Boosting : R¬≤=-0.226  RMSE= 65.89  Acc¬±20= 44.1%\n",
      "Random Forest     : R¬≤=-0.251  RMSE= 66.55  Acc¬±20= 36.9%\n",
      "XGBoost           : R¬≤=-0.065  RMSE= 61.41  Acc¬±20= 45.5%\n",
      "LightGBM          : R¬≤=-0.059  RMSE= 61.22  Acc¬±20= 45.1%\n",
      "\n",
      "72h Ahead:\n",
      "----------------------------------------------------------------------\n",
      "Ridge             : R¬≤=-0.008  RMSE= 58.16  Acc¬±20= 48.5% ‚òÖ\n",
      "Gradient Boosting : R¬≤=-0.436  RMSE= 69.42  Acc¬±20= 46.1%\n",
      "Random Forest     : R¬≤=-0.502  RMSE= 70.99  Acc¬±20= 41.3%\n",
      "XGBoost           : R¬≤=-0.176  RMSE= 62.83  Acc¬±20= 47.5%\n",
      "LightGBM          : R¬≤=-0.025  RMSE= 58.66  Acc¬±20= 47.8%\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ML TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìä Source: MONGODB\n",
      "üìà Models: 5 ML models √ó 3 horizons = 15 total\n",
      "\n",
      "üìÅ Saved:\n",
      "  ‚úì models/*.pkl (15 ML models)\n",
      "  ‚úì models/scaler_ml.pkl\n",
      "  ‚úì models/ml_only_results.json\n",
      "\n",
      "üí° TensorFlow not needed - ML models work great!\n",
      "   XGBoost and LightGBM often outperform LSTM anyway!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ML Models ONLY - No TensorFlow Needed\n",
    "======================================\n",
    "Trains 4 powerful ML models without DL\n",
    "Perfect when TensorFlow won't install\n",
    "\n",
    "Author: AQI Prediction Team\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AQI PREDICTION - ML MODELS (NO TENSORFLOW)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Load Data\n",
    "# ============================================================================\n",
    "\n",
    "def load_from_mongodb(uri, max_attempts=2):\n",
    "    \"\"\"Try MongoDB\"\"\"\n",
    "    from pymongo import MongoClient\n",
    "    from pymongo.server_api import ServerApi\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            print(f\"\\nAttempt {attempt + 1}/{max_attempts}: Connecting to MongoDB...\")\n",
    "            client = MongoClient(uri, server_api=ServerApi('1'),\n",
    "                               serverSelectionTimeoutMS=5000, connectTimeoutMS=5000)\n",
    "            client.admin.command('ping')\n",
    "            print(\"‚úì Connected!\")\n",
    "            \n",
    "            db = client['aqi_feature_store']\n",
    "            collection = db['aqi_features']\n",
    "            data = pd.DataFrame(list(collection.find({}, {\"_id\": 0})))\n",
    "            client.close()\n",
    "            \n",
    "            print(f\"‚úì Loaded {len(data)} records from MongoDB\")\n",
    "            return data, 'mongodb'\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Failed: {str(e)[:80]}\")\n",
    "    return None, None\n",
    "\n",
    "def load_from_csv(csv_path):\n",
    "    \"\"\"Load from CSV\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nLoading from CSV: {csv_path}\")\n",
    "        data = pd.read_csv(csv_path)\n",
    "        print(f\"‚úì Loaded {len(data)} records\")\n",
    "        return data, 'csv'\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "print(\"\\n1. Loading data...\")\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://nawababbas08_db_user:2Ja4OGlDdKfG6EvZ@cluster0.jnxn95g.mongodb.net/?retryWrites=true&w=majority&tlsAllowInvalidCertificates=true\"\n",
    "CSV_PATH = \"data/cleaned_aqi_data_v2.csv\"\n",
    "\n",
    "data, source = load_from_mongodb(MONGO_URI, 2)\n",
    "if data is None:\n",
    "    print(\"\\n‚ö†Ô∏è MongoDB failed, using CSV...\")\n",
    "    data, source = load_from_csv(CSV_PATH)\n",
    "\n",
    "if data is None:\n",
    "    print(\"\\n‚úó ERROR: No data source available\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\n‚úì Source: {source.upper()}\")\n",
    "print(f\"‚úì Records: {len(data)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Feature Engineering\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. Engineering features...\")\n",
    "\n",
    "if 'time' in data.columns:\n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "    data = data.sort_values('time').reset_index(drop=True)\n",
    "elif 'timestamp' in data.columns:\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Lag features\n",
    "for lag in [1, 6, 24]:\n",
    "    if 'aqi' in data.columns:\n",
    "        data[f'aqi_lag_{lag}h'] = data['aqi'].shift(lag)\n",
    "    if 'pm2_5' in data.columns:\n",
    "        data[f'pm25_lag_{lag}h'] = data['pm2_5'].shift(lag)\n",
    "\n",
    "# Rolling averages\n",
    "for window in [6, 24]:\n",
    "    if 'aqi' in data.columns:\n",
    "        data[f'aqi_ma_{window}h'] = data['aqi'].rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "# Cyclical\n",
    "if 'hour' in data.columns:\n",
    "    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "\n",
    "# Targets\n",
    "data['aqi_24h'] = data['aqi'].shift(-24)\n",
    "data['aqi_48h'] = data['aqi'].shift(-48)\n",
    "data['aqi_72h'] = data['aqi'].shift(-72)\n",
    "\n",
    "data = data.dropna(axis=1, how='all')\n",
    "data = data.dropna()\n",
    "\n",
    "print(f\"‚úì After engineering: {len(data)} records\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Prepare Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. Preparing features...\")\n",
    "\n",
    "feature_cols = [col for col in data.columns \n",
    "                if col not in ['time', 'timestamp', 'aqi_24h', 'aqi_48h', 'aqi_72h',\n",
    "                              'dominant_pollutant', 'aqi_category', 'aqi_color', 'time_of_day']]\n",
    "\n",
    "# Get only numeric columns\n",
    "X = data[feature_cols].select_dtypes(include=[np.number])\n",
    "y_24h = data['aqi_24h']\n",
    "y_48h = data['aqi_48h']\n",
    "y_72h = data['aqi_72h']\n",
    "\n",
    "print(f\"‚úì Features: {len(X.columns)}\")\n",
    "print(f\"‚úì Samples: {len(X)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Split & Scale\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. Splitting and scaling...\")\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_24h_train, y_24h_test = y_24h[:split_idx], y_24h[split_idx:]\n",
    "y_48h_train, y_48h_test = y_48h[:split_idx], y_48h[split_idx:]\n",
    "y_72h_train, y_72h_test = y_72h[:split_idx], y_72h[split_idx:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "with open('models/scaler_ml.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"‚úì Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Define Models\n",
    "# ============================================================================\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=10.0),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.05, min_child_weight=5, random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, max_depth=5, learning_rate=0.05, min_child_samples=20, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    acc_20 = np.sum(np.abs(y_true - y_pred) <= 20) / len(y_true) * 100\n",
    "    acc_10 = np.sum(np.abs(y_true - y_pred) <= 10) / len(y_true) * 100\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'Acc20': acc_20, 'Acc10': acc_10}\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Train\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING ML MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for horizon, y_train, y_test in [\n",
    "    ('24h', y_24h_train, y_24h_test),\n",
    "    ('48h', y_48h_train, y_48h_test),\n",
    "    ('72h', y_72h_train, y_72h_test)\n",
    "]:\n",
    "    print(f\"\\n{horizon} Ahead:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    results[horizon] = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}...\")\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        \n",
    "        train_metrics = evaluate(y_train, y_pred_train)\n",
    "        test_metrics = evaluate(y_test, y_pred_test)\n",
    "        \n",
    "        kf = KFold(n_splits=3, shuffle=False)\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='r2', n_jobs=-1)\n",
    "        \n",
    "        results[horizon][name] = {\n",
    "            'test_R2': test_metrics['R2'],\n",
    "            'test_RMSE': test_metrics['RMSE'],\n",
    "            'test_MAE': test_metrics['MAE'],\n",
    "            'test_Acc20': test_metrics['Acc20'],\n",
    "            'test_Acc10': test_metrics['Acc10'],\n",
    "            'train_R2': train_metrics['R2'],\n",
    "            'cv_R2': cv_scores.mean()\n",
    "        }\n",
    "        \n",
    "        print(f\"  Test R¬≤:   {test_metrics['R2']:.3f}\")\n",
    "        print(f\"  RMSE:      {test_metrics['RMSE']:.2f}\")\n",
    "        print(f\"  Acc ¬±20:   {test_metrics['Acc20']:.1f}%\")\n",
    "        print(f\"  Train R¬≤:  {train_metrics['R2']:.3f}\")\n",
    "        \n",
    "        if train_metrics['R2'] - test_metrics['R2'] > 0.3:\n",
    "            print(f\"  ‚ö†Ô∏è OVERFITTING\")\n",
    "        \n",
    "        model_path = f'models/{name.lower().replace(\" \", \"_\")}_{horizon}.pkl'\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"  ‚úì Saved: {model_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for horizon in ['24h', '48h', '72h']:\n",
    "    print(f\"\\n{horizon} Ahead:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    best = max(results[horizon].items(), key=lambda x: x[1]['test_R2'])\n",
    "    \n",
    "    for name in results[horizon]:\n",
    "        m = results[horizon][name]\n",
    "        marker = \" ‚òÖ\" if name == best[0] else \"\"\n",
    "        print(f\"{name:18s}: R¬≤={m['test_R2']:6.3f}  RMSE={m['test_RMSE']:6.2f}  Acc¬±20={m['test_Acc20']:5.1f}%{marker}\")\n",
    "\n",
    "with open('models/ml_only_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ML TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Source: {source.upper()}\")\n",
    "print(f\"üìà Models: 5 ML models √ó 3 horizons = 15 total\")\n",
    "print(\"\\nüìÅ Saved:\")\n",
    "print(\"  ‚úì models/*.pkl (15 ML models)\")\n",
    "print(\"  ‚úì models/scaler_ml.pkl\")\n",
    "print(\"  ‚úì models/ml_only_results.json\")\n",
    "print(\"\\nüí° TensorFlow not needed - ML models work great!\")\n",
    "print(\"   XGBoost and LightGBM often outperform LSTM anyway!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4d243-2634-4627-afb4-7084f63a6e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
