{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d447af8c-ab20-4980-8b40-6d1c5f0ff541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting AQI data for Karachi (last 180 days)...\n",
      "\n",
      "Dataset saved: data/cleaned_aqi_data_v2.csv\n",
      "Records: 4,340\n",
      "Features: 47\n",
      "Date range: 2025-08-20 00:00:00+00:00 to 2026-02-16 19:00:00+00:00\n",
      "Mean AQI: 102.0\n",
      "Max AQI: 500\n",
      "\n",
      "AQI Distribution:\n",
      "  Moderate: 2565 (59.1%)\n",
      "  Unhealthy for Sensitive Groups: 1244 (28.7%)\n",
      "  Unhealthy: 371 (8.5%)\n",
      "  Good: 98 (2.3%)\n",
      "  Hazardous: 62 (1.4%)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "LATITUDE = 24.8607\n",
    "LONGITUDE = 67.0011\n",
    "CITY_NAME = \"Karachi\"\n",
    "AQICN_API_TOKEN = \"6fd579d03bc442add85f9d948a9a05424f8d5fbb\"\n",
    "PAST_DAYS = 180\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "def fetch_aqicn_current(lat, lon, token, city_name):\n",
    "    \"\"\"Fetch current AQI data from AQICN API\"\"\"\n",
    "    url = f\"https://api.waqi.info/feed/{city_name}/\"\n",
    "    params = {'token': token}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == 'ok':\n",
    "            return data['data']\n",
    "        \n",
    "        # Fallback to coordinates\n",
    "        url = f\"https://api.waqi.info/feed/geo:{lat};{lon}/\"\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == 'ok':\n",
    "            return data['data']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching AQICN data: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fetch_open_meteo(lat, lon, past_days):\n",
    "    \"\"\"Fetch air quality data from Open-Meteo\"\"\"\n",
    "    url = (\n",
    "        \"https://air-quality-api.open-meteo.com/v1/air-quality\"\n",
    "        f\"?latitude={lat}&longitude={lon}\"\n",
    "        \"&hourly=pm2_5,pm10,nitrogen_dioxide,ozone,sulphur_dioxide,carbon_monoxide\"\n",
    "        f\"&past_days={past_days}&timezone=UTC\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        df = pd.DataFrame(data[\"hourly\"])\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True)\n",
    "        df = df[df[\"time\"] <= pd.Timestamp.utcnow()]\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching pollution data: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_weather_data(lat, lon, start_date, end_date):\n",
    "    \"\"\"Fetch weather data from Meteostat\"\"\"\n",
    "    try:\n",
    "        import meteostat as ms\n",
    "        \n",
    "        stations = ms.stations.nearby(ms.Point(lat, lon), limit=5)\n",
    "        if stations.empty:\n",
    "            return None\n",
    "        \n",
    "        station_id = stations.index[0]\n",
    "        ts = ms.hourly(station_id, start_date, end_date, timezone=\"UTC\")\n",
    "        weather_df = ts.fetch()\n",
    "        \n",
    "        if weather_df is None or weather_df.empty:\n",
    "            return None\n",
    "        \n",
    "        weather_df = weather_df.reset_index()\n",
    "        if 'time' not in weather_df.columns:\n",
    "            weather_df = weather_df.rename(columns={weather_df.columns[0]: 'time'})\n",
    "        \n",
    "        weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "        return weather_df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def calculate_pm25_aqi(pm25):\n",
    "    \"\"\"Calculate AQI from PM2.5 concentration\"\"\"\n",
    "    if pd.isna(pm25) or pm25 < 0:\n",
    "        return np.nan\n",
    "    \n",
    "    breakpoints = [\n",
    "        (0.0, 12.0, 0, 50),\n",
    "        (12.1, 35.4, 51, 100),\n",
    "        (35.5, 55.4, 101, 150),\n",
    "        (55.5, 150.4, 151, 200),\n",
    "        (150.5, 250.4, 201, 300),\n",
    "        (250.5, 500.4, 301, 500),\n",
    "    ]\n",
    "    \n",
    "    for C_low, C_high, I_low, I_high in breakpoints:\n",
    "        if C_low <= pm25 <= C_high:\n",
    "            aqi = ((I_high - I_low) / (C_high - C_low)) * (pm25 - C_low) + I_low\n",
    "            return round(aqi)\n",
    "    \n",
    "    return 500\n",
    "\n",
    "def calculate_pm10_aqi(pm10):\n",
    "    \"\"\"Calculate AQI from PM10 concentration\"\"\"\n",
    "    if pd.isna(pm10) or pm10 < 0:\n",
    "        return np.nan\n",
    "    \n",
    "    breakpoints = [\n",
    "        (0, 54, 0, 50),\n",
    "        (55, 154, 51, 100),\n",
    "        (155, 254, 101, 150),\n",
    "        (255, 354, 151, 200),\n",
    "        (355, 424, 201, 300),\n",
    "        (425, 604, 301, 500),\n",
    "    ]\n",
    "    \n",
    "    for C_low, C_high, I_low, I_high in breakpoints:\n",
    "        if C_low <= pm10 <= C_high:\n",
    "            aqi = ((I_high - I_low) / (C_high - C_low)) * (pm10 - C_low) + I_low\n",
    "            return round(aqi)\n",
    "    \n",
    "    return 500\n",
    "\n",
    "def get_aqi_category(aqi):\n",
    "    \"\"\"Get AQI category from value\"\"\"\n",
    "    if pd.isna(aqi):\n",
    "        return 'Unknown'\n",
    "    elif aqi <= 50:\n",
    "        return 'Good'\n",
    "    elif aqi <= 100:\n",
    "        return 'Moderate'\n",
    "    elif aqi <= 150:\n",
    "        return 'Unhealthy for Sensitive Groups'\n",
    "    elif aqi <= 200:\n",
    "        return 'Unhealthy'\n",
    "    elif aqi <= 300:\n",
    "        return 'Very Unhealthy'\n",
    "    else:\n",
    "        return 'Hazardous'\n",
    "\n",
    "def get_aqi_color(aqi):\n",
    "    \"\"\"Get color code for AQI\"\"\"\n",
    "    if pd.isna(aqi):\n",
    "        return 'gray'\n",
    "    elif aqi <= 50:\n",
    "        return 'green'\n",
    "    elif aqi <= 100:\n",
    "        return 'yellow'\n",
    "    elif aqi <= 150:\n",
    "        return 'orange'\n",
    "    elif aqi <= 200:\n",
    "        return 'red'\n",
    "    elif aqi <= 300:\n",
    "        return 'purple'\n",
    "    else:\n",
    "        return 'maroon'\n",
    "\n",
    "def add_time_features(df):\n",
    "    \"\"\"Add time-based features\"\"\"\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['day_of_week'] = df['time'].dt.dayofweek\n",
    "    df['day_of_month'] = df['time'].dt.day\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['day_of_year'] = df['time'].dt.dayofyear\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    def get_time_of_day(hour):\n",
    "        if 6 <= hour < 12:\n",
    "            return 'morning'\n",
    "        elif 12 <= hour < 17:\n",
    "            return 'afternoon'\n",
    "        elif 17 <= hour < 21:\n",
    "            return 'evening'\n",
    "        else:\n",
    "            return 'night'\n",
    "    \n",
    "    df['time_of_day'] = df['hour'].apply(get_time_of_day)\n",
    "    \n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'summer'\n",
    "        else:\n",
    "            return 'fall'\n",
    "    \n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df):\n",
    "    \"\"\"Add lag features for time series\"\"\"\n",
    "    for lag in [1, 3, 6, 12, 24]:\n",
    "        df[f'aqi_lag_{lag}h'] = df['aqi'].shift(lag)\n",
    "    \n",
    "    for lag in [1, 6, 24]:\n",
    "        df[f'pm25_lag_{lag}h'] = df['pm2_5'].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_rolling_features(df):\n",
    "    \"\"\"Add rolling statistics\"\"\"\n",
    "    for window in [6, 12, 24]:\n",
    "        df[f'aqi_ma_{window}h'] = df['aqi'].rolling(window=window, min_periods=1).mean()\n",
    "        df[f'aqi_std_{window}h'] = df['aqi'].rolling(window=window, min_periods=1).std()\n",
    "    \n",
    "    for window in [6, 24]:\n",
    "        df[f'pm25_ma_{window}h'] = df['pm2_5'].rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    print(f\"Collecting AQI data for {CITY_NAME} (last {PAST_DAYS} days)...\")\n",
    "    \n",
    "    # Fetch pollution data\n",
    "    pollution_df = fetch_open_meteo(LATITUDE, LONGITUDE, PAST_DAYS)\n",
    "    if pollution_df is None:\n",
    "        print(\"Failed to fetch pollution data\")\n",
    "        return\n",
    "    \n",
    "    # Calculate AQI\n",
    "    pollution_df['aqi_pm25'] = pollution_df['pm2_5'].apply(calculate_pm25_aqi)\n",
    "    pollution_df['aqi_pm10'] = pollution_df['pm10'].apply(calculate_pm10_aqi)\n",
    "    pollution_df['aqi'] = pollution_df[['aqi_pm25', 'aqi_pm10']].max(axis=1)\n",
    "    \n",
    "    # Fetch weather data\n",
    "    start_date = pollution_df['time'].min()\n",
    "    end_date = pollution_df['time'].max()\n",
    "    weather_df = fetch_weather_data(LATITUDE, LONGITUDE, start_date, end_date)\n",
    "    \n",
    "    # Merge data\n",
    "    pollution_df['time'] = pollution_df['time'].dt.floor('h')\n",
    "    \n",
    "    if weather_df is not None:\n",
    "        weather_df['time'] = pd.to_datetime(weather_df['time']).dt.floor('h')\n",
    "        merged_df = pollution_df.merge(weather_df, on='time', how='left')\n",
    "    else:\n",
    "        merged_df = pollution_df.copy()\n",
    "    \n",
    "    # Add features\n",
    "    merged_df = add_time_features(merged_df)\n",
    "    merged_df = add_lag_features(merged_df)\n",
    "    merged_df = add_rolling_features(merged_df)\n",
    "    merged_df['aqi_category'] = merged_df['aqi'].apply(get_aqi_category)\n",
    "    merged_df['aqi_color'] = merged_df['aqi'].apply(get_aqi_color)\n",
    "    \n",
    "    # Handle missing values\n",
    "    numeric_cols = merged_df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if merged_df[col].isnull().sum() > 0:\n",
    "            merged_df[col] = merged_df[col].interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "    merged_df = merged_df.ffill().bfill()\n",
    "    \n",
    "    # Save dataset\n",
    "    output_path = \"data/cleaned_aqi_data_v2.csv\"\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nDataset saved: {output_path}\")\n",
    "    print(f\"Records: {len(merged_df):,}\")\n",
    "    print(f\"Features: {len(merged_df.columns)}\")\n",
    "    print(f\"Date range: {merged_df['time'].min()} to {merged_df['time'].max()}\")\n",
    "    print(f\"Mean AQI: {merged_df['aqi'].mean():.1f}\")\n",
    "    print(f\"Max AQI: {merged_df['aqi'].max():.0f}\")\n",
    "    print(\"\\nAQI Distribution:\")\n",
    "    for category, count in merged_df['aqi_category'].value_counts().items():\n",
    "        print(f\"  {category}: {count} ({count/len(merged_df)*100:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221b227c-491d-459b-a1ce-394cb4f27a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_aqi_data_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c15e08-4504-483c-8838-dcf957d3017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'pm2_5', 'pm10', 'nitrogen_dioxide', 'ozone', 'sulphur_dioxide',\n",
       "       'carbon_monoxide', 'aqi_pm25', 'aqi_pm10', 'aqi', 'temp', 'rhum',\n",
       "       'prcp', 'snwd', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'cldc', 'coco',\n",
       "       'hour', 'day_of_week', 'day_of_month', 'month', 'day_of_year',\n",
       "       'is_weekend', 'time_of_day', 'season', 'aqi_lag_1h', 'aqi_lag_3h',\n",
       "       'aqi_lag_6h', 'aqi_lag_12h', 'aqi_lag_24h', 'pm25_lag_1h',\n",
       "       'pm25_lag_6h', 'pm25_lag_24h', 'aqi_ma_6h', 'aqi_std_6h', 'aqi_ma_12h',\n",
       "       'aqi_std_12h', 'aqi_ma_24h', 'aqi_std_24h', 'pm25_ma_6h', 'pm25_ma_24h',\n",
       "       'aqi_category', 'aqi_color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22850bce-7f74-4e4b-9954-af1d65a38729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
