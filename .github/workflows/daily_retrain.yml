name: Daily Model Retraining

on:
  schedule:
    - cron: '*/20 * * * *'
  workflow_dispatch:

jobs:
  retrain:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GH_PAT }}

    - uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - run: pip install jupyter nbconvert pandas numpy scikit-learn xgboost lightgbm pymongo "pymongo[srv]" dnspython requests meteostat

    - name: Fetch
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: jupyter nbconvert --to python Scripts/Fetch_latest_data.ipynb --stdout | python || true
      continue-on-error: true

    - name: Clean
      run: jupyter nbconvert --to python Scripts/clean_data.ipynb --stdout | python || true
      continue-on-error: true

    - name: Train
      run: |
        python - <<'EOF'
        import pandas as pd, numpy as np, pickle, os
        from sklearn.ensemble import GradientBoostingRegressor
        from sklearn.preprocessing import StandardScaler
        import xgboost as xgb, lightgbm as lgb
        
        df = pd.read_csv('data/cleaned_aqi_data_v2.csv')
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time')
        
        # Keep only last 2000 rows for speed
        df = df.tail(2000)
        
        # Create target
        df['aqi_24h'] = df['aqi'].shift(-24)
        df = df.dropna(subset=['aqi_24h'])
        
        # Features: only numeric, exclude target
        X = df.select_dtypes(include=[np.number]).drop(['aqi_24h'], axis=1, errors='ignore')
        y = df['aqi_24h']
        
        # Remove any NaN
        mask = ~(X.isna().any(axis=1) | y.isna())
        X, y = X[mask], y[mask]
        
        print(f"Data: {len(X)} rows, {len(X.columns)} features")
        
        if len(X) < 100:
            print("ERROR: Not enough data")
            exit(1)
        
        split = int(len(X)*0.8)
        X_train, X_test = X[:split], X[split:]
        y_train, y_test = y[:split], y[split:]
        
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        
        os.makedirs('models', exist_ok=True)
        
        for name, model in [
            ('xgboost', xgb.XGBRegressor(n_estimators=30, max_depth=3, random_state=42)),
            ('lightgbm', lgb.LGBMRegressor(n_estimators=30, max_depth=3, random_state=42, verbose=-1))
        ]:
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            with open(f'models/{name}_24h.pkl', 'wb') as f:
                pickle.dump(model, f)
            print(f"âœ“ {name}: RÂ²={score:.3f}")
        
        with open('models/scaler_ml.pkl', 'wb') as f:
            pickle.dump(scaler, f)
        EOF

    - name: Commit
      run: |
        git config user.email "bot@github.com"
        git config user.name "Bot"
        git add models/ data/ || true
        git diff --staged --quiet || git commit -m "ðŸ¤– $(date +'%Y-%m-%d %H:%M')" && git push || true
