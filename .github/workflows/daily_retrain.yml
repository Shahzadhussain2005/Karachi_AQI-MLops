name: Daily Data Collection & Model Training

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  data-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GH_PAT }}
        fetch-depth: 0

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install packages
      run: |
        pip install jupyter nbconvert pandas numpy scikit-learn xgboost lightgbm pymongo "pymongo[srv]" dnspython requests python-dotenv meteostat

    - name: List files
      run: |
        echo "=== Scripts/ ==="
        ls -la Scripts/ 2>/dev/null || echo "Not found"

    - name: Fetch latest AQI data
      run: |
        echo "üì° Fetching data..."
        jupyter nbconvert --to script "Scripts/Fetch_latest_data.ipynb" --output /tmp/fetch
        python /tmp/fetch.py
      continue-on-error: true

    - name: Clean data
      run: |
        echo "üßπ Cleaning data..."
        jupyter nbconvert --to script "Scripts/clean_data.ipynb" --output /tmp/clean
        python /tmp/clean.py
      continue-on-error: true

    - name: Upload to MongoDB
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: |
        echo "‚òÅÔ∏è Uploading to MongoDB..."
        jupyter nbconvert --to script "Scripts/mongodb_connect.ipynb" --output /tmp/mongo
        python /tmp/mongo.py
      continue-on-error: true

    - name: Train models
      run: |
        echo "ü§ñ Training models..."
        jupyter nbconvert --to script "Scripts/train_models.ipynb" --output /tmp/train
        python /tmp/train.py

    - name: Prepare dashboard data
      run: |
        python - <<'EOF'
        import pandas as pd
        import os
        for csv in ['data/cleaned_aqi_data_v3.csv','data/cleaned_aqi_data_v2.csv']:
            if os.path.exists(csv):
                df = pd.read_csv(csv).tail(720)
                df.to_csv('data/historical_aqi.csv', index=False)
                print(f"‚úì Dashboard: {len(df)} rows from {csv}")
                break
        EOF

    - name: Check results
      run: |
        echo "=== Results ==="
        ls -lh data/*.csv 2>/dev/null || true
        ls -lh Scripts/models/*.pkl 2>/dev/null || true
        ls -lh models/*.pkl 2>/dev/null || true

    - name: Commit changes
      run: |
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git add Scripts/models/ models/ data/ 2>/dev/null || true
        git diff --staged --quiet || {
          git commit -m "ü§ñ Daily pipeline: $(date +'%Y-%m-%d %H:%M UTC')"
          git push origin main
          echo "‚úì Pushed to GitHub"
        }

    - name: Summary
      if: always()
      run: |
        echo "================================================"
        echo "PIPELINE COMPLETE"
        echo "================================================"
        echo "‚úì Fetched data"
        echo "‚úì Cleaned data"
        echo "‚úì Uploaded to MongoDB"
        echo "‚úì Trained models"
        echo "‚úì Updated dashboard"
        echo "‚úì Committed to GitHub"
        echo "Next run: Tomorrow 00:00 UTC"
        echo "================================================"
