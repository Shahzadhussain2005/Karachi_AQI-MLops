name: Daily Data Collection & Model Training
on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  data-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GH_PAT }}
        fetch-depth: 0
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install packages
      run: |
        pip install jupyter nbconvert pandas numpy scikit-learn xgboost lightgbm pymongo "pymongo[srv]" dnspython requests python-dotenv meteostat
    
    - name: List files
      run: |
        echo "=== Scripts/ ==="
        ls -la Scripts/ 2>/dev/null || echo "Not found"
    
    - name: Fetch latest AQI data
      run: |
        echo "üì° Fetching data..."
        jupyter nbconvert --to script "Scripts/Fetch_latest_data.ipynb" --output /tmp/fetch
        python /tmp/fetch.py
      continue-on-error: true
    
    - name: Clean data
      run: |
        echo "üßπ Cleaning data..."
        jupyter nbconvert --to script "Scripts/clean_data.ipynb" --output /tmp/clean
        python /tmp/clean.py
      continue-on-error: true
    
    - name: Upload to MongoDB
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: |
        echo "‚òÅÔ∏è Uploading to MongoDB..."
        jupyter nbconvert --to script "Scripts/mongodb_connect.ipynb" --output /tmp/mongo
        python /tmp/mongo.py
      continue-on-error: true
    
    - name: Train ML models (Optimized)
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: |
        echo "ü§ñ Training ML models with hyperparameter tuning..."
        echo "üìä Training 6 models √ó 3 horizons (24h, 48h, 72h)"
        echo "‚è±Ô∏è  Expected time: 10-20 minutes"
        jupyter nbconvert --to script "Scripts/models.ipynb" --output /tmp/models
        python /tmp/models.py
    
    - name: Prepare dashboard data
      run: |
        python - <<'EOF'
        import pandas as pd
        import os
        for csv in ['data/cleaned_aqi_data_v3.csv','data/cleaned_aqi_data_v2.csv']:
            if os.path.exists(csv):
                df = pd.read_csv(csv).tail(720)
                df.to_csv('data/historical_aqi.csv', index=False)
                print(f"‚úì Dashboard: {len(df)} rows from {csv}")
                break
        EOF
    
    - name: Check results
      run: |
        echo "=== Results ==="
        ls -lh data/*.csv 2>/dev/null || true
        echo ""
        echo "=== Trained Models ==="
        ls -lh models/*.pkl 2>/dev/null || true
        echo ""
        echo "=== Model Results ==="
        cat models/ml_tuned_results.json 2>/dev/null || echo "Results file not found"
    
    - name: Commit changes
      run: |
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git add models/ data/ 2>/dev/null || true
        git diff --staged --quiet || {
          git commit -m "ü§ñ Daily pipeline: $(date +'%Y-%m-%d %H:%M UTC')"
          git push origin main
          echo "‚úì Pushed to GitHub"
        }
    
    - name: Summary
      if: always()
      run: |
        echo "================================================"
        echo "PIPELINE COMPLETE"
        echo "================================================"
        echo "‚úì Fetched data"
        echo "‚úì Cleaned data"
        echo "‚úì Uploaded to MongoDB"
        echo "‚úì Trained 18 ML models (6 models √ó 3 horizons)"
        echo "‚úì Updated dashboard"
        echo "‚úì Committed to GitHub"
        echo "Next run: Tomorrow 00:00 UTC"
        echo "================================================"
