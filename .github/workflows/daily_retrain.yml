name: Daily Model Retraining

on:
  schedule:
    - cron: '*/20 * * * *'
  workflow_dispatch:

jobs:
  retrain:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GH_PAT }}

    - uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - run: pip install jupyter nbconvert pandas numpy scikit-learn xgboost lightgbm pymongo "pymongo[srv]" dnspython requests meteostat

    - name: Fetch
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: jupyter nbconvert --to python Scripts/Fetch_latest_data.ipynb --stdout | python || true
      continue-on-error: true

    - name: Clean
      run: jupyter nbconvert --to python Scripts/clean_data.ipynb --stdout | python || true
      continue-on-error: true

    - name: Train
      run: |
        python - <<'EOF'
        import pandas as pd, numpy as np, pickle, os
        from sklearn.preprocessing import StandardScaler
        import xgboost as xgb, lightgbm as lgb
        
        df = pd.read_csv('data/cleaned_aqi_data_v2.csv')
        print(f"Loaded: {len(df)} rows, {len(df.columns)} cols")
        
        # Fill ALL missing values first
        df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)
        
        # Keep numeric only
        numeric_df = df.select_dtypes(include=[np.number])
        print(f"Numeric: {len(numeric_df.columns)} cols")
        
        # Must have 'aqi' column
        if 'aqi' not in numeric_df.columns:
            print("ERROR: No 'aqi' column")
            exit(1)
        
        # Create target - use last 1500 rows only
        data = numeric_df.tail(1500).copy()
        data['target'] = data['aqi'].shift(-24)
        
        # Drop last 24 rows (no target)
        data = data[:-24]
        
        X = data.drop(['target'], axis=1)
        y = data['target']
        
        print(f"Final: {len(X)} rows, {len(X.columns)} features")
        
        if len(X) < 100:
            print("ERROR: Not enough data after processing")
            exit(1)
        
        split = int(len(X)*0.8)
        X_train, X_test = X.iloc[:split], X.iloc[split:]
        y_train, y_test = y.iloc[:split], y.iloc[split:]
        
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        
        os.makedirs('models', exist_ok=True)
        
        for name, model in [
            ('xgboost', xgb.XGBRegressor(n_estimators=30, max_depth=3, random_state=42)),
            ('lightgbm', lgb.LGBMRegressor(n_estimators=30, max_depth=3, random_state=42, verbose=-1))
        ]:
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            with open(f'models/{name}_24h.pkl', 'wb') as f:
                pickle.dump(model, f)
            print(f"âœ“ {name}: RÂ²={score:.3f}")
        
        with open('models/scaler_ml.pkl', 'wb') as f:
            pickle.dump(scaler, f)
        print("âœ“ All models saved")
        EOF

    - name: Commit
      run: |
        git config user.email "bot@github.com"
        git config user.name "Bot"
        git add models/ || true
        git diff --staged --quiet || git commit -m "ðŸ¤– $(date +'%Y-%m-%d %H:%M')" && git push || true
