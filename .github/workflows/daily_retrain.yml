name: Daily Model Retraining (CI Only)

on:
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight UTC
  workflow_dispatch:  # Manual trigger

jobs:
  retrain-models:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GH_PAT }}
        fetch-depth: 0
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install jupyter nbconvert pandas numpy scikit-learn xgboost lightgbm pymongo "pymongo[srv]" dnspython requests python-dotenv meteostat
    
    - name: Verify files
      run: |
        echo "=== Repository Structure ==="
        ls -la
        echo ""
        echo "=== Scripts Directory ==="
        ls -la Scripts/ 2>/dev/null || echo "Scripts/ not found"
        echo ""
        echo "=== Data Directory ==="
        ls -la data/ 2>/dev/null || echo "data/ not found"
    
    - name: Fetch latest AQI data
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: |
        echo "üì° Fetching latest AQI data..."
        jupyter nbconvert --to script "Scripts/Fetch_latest_data.ipynb" --output /tmp/fetch --log-level ERROR
        python /tmp/fetch.py || echo "‚ö†Ô∏è Fetch failed, continuing..."
      continue-on-error: true
    
    - name: Clean and prepare data
      run: |
        echo "üßπ Cleaning data..."
        jupyter nbconvert --to script "Scripts/clean_data.ipynb" --output /tmp/clean --log-level ERROR
        python /tmp/clean.py || echo "‚ö†Ô∏è Clean failed, continuing..."
      continue-on-error: true
    
    - name: Upload to MongoDB
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: |
        echo "‚òÅÔ∏è Uploading to MongoDB..."
        if [ -f "Scripts/mongodb_connect.ipynb" ]; then
          jupyter nbconvert --to script "Scripts/mongodb_connect.ipynb" --output /tmp/mongo --log-level ERROR
          python /tmp/mongo.py || echo "‚ö†Ô∏è MongoDB upload failed, continuing..."
        else
          echo "‚ÑπÔ∏è mongodb_connect.ipynb not found, skipping..."
        fi
      continue-on-error: true
    
    - name: Train ML models (Optimized)
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
      run: |
        echo "ü§ñ Training ML models..."
        echo "üìä Training 6 models √ó 3 horizons (24h, 48h, 72h)"
        echo "‚è±Ô∏è  Expected time: 10-20 minutes"
        
        if [ -f "Scripts/models.ipynb" ]; then
          echo "Using models.ipynb..."
          jupyter nbconvert --to script "Scripts/models.ipynb" --output /tmp/train --log-level ERROR
          python /tmp/train.py
        elif [ -f "Scripts/train_model.py" ]; then
          echo "Using train_model.py..."
          python Scripts/train_model.py
        else
          echo "‚ùå No training script found!"
          echo "Expected: Scripts/models.ipynb or Scripts/train_model.py"
          exit 1
        fi
    
    - name: Verify trained models
      run: |
        echo "=== Checking Results ==="
        echo ""
        echo "Data files:"
        ls -lh data/*.csv 2>/dev/null || echo "No CSV files found"
        echo ""
        echo "Model files:"
        ls -lh models/*.pkl 2>/dev/null || echo "No model files found"
        echo ""
        echo "Results file:"
        if [ -f "models/ml_tuned_results.json" ]; then
          echo "‚úì Results file exists"
          head -20 models/ml_tuned_results.json
        else
          echo "‚ö†Ô∏è No results file found"
        fi
        echo ""
        
        # Count models
        model_count=$(ls models/*.pkl 2>/dev/null | wc -l)
        echo "Total models saved: $model_count"
        
        if [ $model_count -eq 0 ]; then
          echo "‚ùå ERROR: No models were saved!"
          exit 1
        else
          echo "‚úÖ Successfully saved $model_count models"
        fi
    
    - name: Prepare dashboard data
      run: |
        echo "üìä Preparing dashboard data..."
        python - <<'PYTHON_SCRIPT'
import pandas as pd
import os

data_files = ['data/cleaned_aqi_data_v3.csv', 'data/cleaned_aqi_data_v2.csv', 'data/cleaned_aqi_data.csv']

for csv_file in data_files:
    if os.path.exists(csv_file):
        try:
            df = pd.read_csv(csv_file)
            df_recent = df.tail(720)  # Last 30 days (24 hours/day)
            df_recent.to_csv('data/historical_aqi.csv', index=False)
            print(f"‚úì Dashboard data: {len(df_recent)} rows from {csv_file}")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è Could not process {csv_file}: {e}")
            continue
else:
    print("‚ö†Ô∏è No data file found for dashboard")
PYTHON_SCRIPT
      continue-on-error: true
    
    - name: Commit and push changes
      run: |
        echo "üíæ Committing changes..."
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git config user.name "GitHub Actions Bot"
        
        # Add model files
        git add models/*.pkl models/*.json models/*.csv 2>/dev/null || true
        
        # Add data files
        git add data/*.csv 2>/dev/null || true
        
        # Check if there are changes
        if git diff --staged --quiet; then
          echo "‚ÑπÔ∏è No changes to commit"
        else
          git commit -m "ü§ñ Daily model retrain: $(date +'%Y-%m-%d %H:%M UTC')"
          git push origin main
          echo "‚úÖ Changes pushed to GitHub"
        fi
    
    - name: Pipeline Summary
      if: always()
      run: |
        echo ""
        echo "========================================"
        echo "    PIPELINE EXECUTION SUMMARY"
        echo "========================================"
        echo ""
        echo "Steps completed:"
        echo "  ‚úì Data fetch"
        echo "  ‚úì Data cleaning"
        echo "  ‚úì MongoDB upload"
        echo "  ‚úì Model training"
        echo "  ‚úì Dashboard prep"
        echo "  ‚úì Git commit"
        echo ""
        
        # Check for models
        if [ -d "models" ] && [ "$(ls -A models/*.pkl 2>/dev/null)" ]; then
          model_count=$(ls models/*.pkl 2>/dev/null | wc -l)
          echo "‚úÖ SUCCESS: $model_count models trained"
        else
          echo "‚ùå WARNING: No models found"
        fi
        
        echo ""
        echo "Next scheduled run: Tomorrow 00:00 UTC"
        echo "========================================"
